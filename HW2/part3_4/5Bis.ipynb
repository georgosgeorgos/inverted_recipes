{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n",
      "Ok\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "# 5bis\n",
    "from lib3 import *\n",
    "from lib5bis import *\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "import csv\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "# external index for recipes\n",
    "# keys ----> number (str)\n",
    "# values ----> recipes identifier (str)\n",
    "with open('dictRecipes.json', 'r') as fp:\n",
    "    \n",
    "    dictRecipes = json.load(fp)\n",
    "\n",
    "data = []\n",
    "\n",
    "# all data order using dictRecipes\n",
    "\n",
    "with open('data.csv') as tsv:\n",
    "    \n",
    "    fieldnames = [\"title\",\"author\",\"serves\",\"prepTime\", \"cookTime\", \"dietary\", \"ingredients\", \"methods\"]\n",
    "    reader = csv.DictReader(tsv, fieldnames=fieldnames, delimiter = \"\\t\")\n",
    "    for row in reader:\n",
    "        temp = []\n",
    "        temp.append([row[\"title\"],row[\"author\"],row[\"serves\"],row[\"prepTime\"], \n",
    "                     row[\"cookTime\"], row[\"dietary\"],row[\"ingredients\"],row[\"methods\"]])\n",
    "        data.extend(temp)\n",
    "\n",
    "# all data normalized (same relative order dictRecipes)\n",
    "\n",
    "with open('d_normalized.json', 'r') as fp:\n",
    "    \n",
    "    d_normalizedDict = json.load(fp)\n",
    "    \n",
    "# fast recipes (same relative order dictRecipes)\n",
    "#keys ----> number (str)\n",
    "#values ----> number [0,1]\n",
    "\n",
    "with open('d8_dict.json', 'r') as fp:\n",
    "    \n",
    "    d8_dict = json.load(fp)\n",
    "\n",
    "# no lactose recipes\n",
    "#keys ----> number (str)\n",
    "#values ----> number [0,1]\n",
    "\n",
    "with open('d9_dict.json', 'r') as fp:\n",
    "    \n",
    "    d9_dict = json.load(fp)\n",
    "\n",
    "# external index for words\n",
    "# keys ----> numbers (str)\n",
    "# values ---> words (str)\n",
    "with open('indexImproved.json', 'r') as fp:\n",
    "    \n",
    "    indices = json.load(fp)\n",
    "    \n",
    "#all necessary information is stored here(same order indexes)    \n",
    "# keys ----> words\n",
    "# values ----> dictionaries where keys ----> numbers related wiht recipes and values ----> (tf*id)*weight\n",
    "with open('wordsDictImproved.json', 'r') as fp:\n",
    "    \n",
    "    wordsDict = json.load(fp)\n",
    "\n",
    "    \n",
    "# inverted index(same order indexes) \n",
    "# keys ----> words\n",
    "# values ----> list with all sorted recipes that contain this word \n",
    "with open('invertedPostImproved.json', 'r') as fp:\n",
    "    \n",
    "    invertedPost = json.load(fp)\n",
    "    \n",
    "\n",
    "print(\"Ok\")\n",
    "\n",
    "\n",
    "# X contains the tf*id frequency for words in every recipe\n",
    "\n",
    "p = len(wordsDict)\n",
    "q = len(d_normalizedDict)\n",
    "\n",
    "X = np.zeros((p,q))\n",
    "\n",
    "f =  open('XcompressImproved.csv', 'r')\n",
    "\n",
    "i = 0\n",
    "for row in f:\n",
    "    x = row.split(\",\")\n",
    "    for j in range(0,len(x)-1,2):\n",
    "        \n",
    "        X[i,int(x[j])] = float(x[j+1])\n",
    "        \n",
    "    i +=1   \n",
    "        \n",
    "f.close()\n",
    "print(\"Ok\")\n",
    "\n",
    "# Xweight contains the (tf*id)*weight frequency for words in every recipe\n",
    "\n",
    "Xweight = np.zeros((p,q))\n",
    "\n",
    "f =  open('XweightCompressImproved.csv', 'r')\n",
    "\n",
    "i = 0\n",
    "for row in f:\n",
    "    x = row.split(\",\")\n",
    "    for j in range(0,len(x)-1,2):\n",
    "        \n",
    "        Xweight[i,int(x[j])] = float(x[j+1])\n",
    "        \n",
    "    i +=1   \n",
    "        \n",
    "f.close()\n",
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_normalizedDict[\"7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_normalized[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_normalized = []\n",
    "d_normalized.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PREPROCESSING ------> improve and save in a file .dat     \n",
    "data_normalized = []\n",
    "\n",
    "c = 0\n",
    "for row in data[1:]:\n",
    "    \n",
    "    temp = []\n",
    "    c = c+1\n",
    "    \n",
    "    if c%100 == 0:\n",
    "        \n",
    "        time.sleep(5)\n",
    "        print(c)\n",
    "    for i in range(len(row)):\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            temp.append(preprocessTitle(row[i]))\n",
    "        else:\n",
    "            temp.append(preprocess(row[i]))\n",
    "    \n",
    "    data_normalized.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[3962]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aubergin',\n",
       " 'parmigian',\n",
       " 'fresh',\n",
       " 'tomato',\n",
       " 'parmigian',\n",
       " 'melanz',\n",
       " 'pomodoro',\n",
       " 'fresco']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessTitle(data[3962][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_normalized.json', 'r') as fp:\n",
    "    \n",
    "    json.dump(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_normalized = []\n",
    "\n",
    "for i in range(len(d_normalizedDict)):\n",
    "    \n",
    "    data_normalized.append(d_normalizedDict[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a set of preprocessed words and initialize wordsDict\n",
    "\n",
    "set_normalized = set()\n",
    "\n",
    "for recipe in data_normalized[1:]:\n",
    "    for category in recipe :\n",
    "        for word in category:\n",
    "            set_normalized.add(word)\n",
    "\n",
    "words = list(set_normalized)\n",
    "\n",
    "wordsDict = {}\n",
    "wordsDict = {str(key):{} for key in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build inverted index\n",
    "\n",
    "for recipe in range(1,len(data_normalized)):\n",
    "                                                            #for argument in d_normalized[recipe+1]:\n",
    "    for category in data_normalized[recipe]:                # conserve the original order\n",
    "            for string in category:\n",
    "                \n",
    "                wordsDict[str(string)][str(recipe)] = wordsDict[str(string)].get(str(recipe),0) + 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_normalized[3962][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frequency normalization + id\n",
    "\n",
    "tot = len(wordsDict)\n",
    "\n",
    "for key in wordsDict:\n",
    "    c = 0\n",
    "    ix = np.log(tot/len(wordsDict[key]))\n",
    "    for key2 in wordsDict[key]:\n",
    "        \n",
    "        c += wordsDict[key][key2]\n",
    "        \n",
    "    for key2 in wordsDict[key]:\n",
    "        \n",
    "        wordsDict[key][key2] = (wordsDict[key][key2]/c)*ix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = BuildMatrix(wordsDict, indices, data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_compress = []\n",
    "p,q = X.shape\n",
    "for i in range(p):\n",
    "    temp = []\n",
    "    for j in range(q):\n",
    "        if X[i][j] != 0:\n",
    "            temp.append([j,X[i][j]])\n",
    "    X_compress.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wordsDictWeight = wordsDict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weighted inverted index\n",
    "# weighted  title +100  ingredient +25 method +10\n",
    "\n",
    "for key in wordsDictWeight:\n",
    "    for key2 in wordsDictWeight[key]:\n",
    "        \n",
    "        title = d_normalizedDict[key2][0]\n",
    "        ingredients = d_normalizedDict[key2][6]\n",
    "        method = d_normalizedDict[key2][7]\n",
    "        if key in title:\n",
    "            \n",
    "           wordsDictWeight[key][key2] = wordsDictWeight[key][key2]*100\n",
    "            \n",
    "        if key in ingredients:\n",
    "            \n",
    "            wordsDictWeight[key][key2] = wordsDictWeight[key][key2]*25\n",
    "            \n",
    "        if key in method:\n",
    "            \n",
    "            wordsDictWeight[key][key2] = wordsDictWeight[key][key2]*10\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time = [\"10 to 30 mins\",\"less than 10 mins\",\"no cooking required\"]\n",
    "   \n",
    "d8 = []\n",
    "d8.append(\"time\")\n",
    "for row in data[1:]:\n",
    "    if row[4] in time:\n",
    "\n",
    "        d8.append(1)\n",
    "    else:\n",
    "        d8.append(0)\n",
    "return d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "milk = [\"lactose\",\"milk\", \"yogurt\", \"cheese\",\"Buttermilk\",\"CreamSome\",\"Cottage\",\"ricotta\",\"Cream\",\"chocolate\",\"ice cream\",\"Butter\",\n",
    "        \"Margarines\",\"butter\",\"Cookies\",\"cakes\",\"pies\",\"pastries\",\"Toffee\", \"butterscotch\",\"caramels\",\"muffins\", \"biscuits\",\n",
    "        \"Pancakes\", \"waffles\",\"mascarpone\",\"double-cream\",\"whipped\",\"yoghurt\",\"parmigiano\",]\n",
    "\n",
    "milk = preprocess(milk)\n",
    "d9 = []\n",
    "d9.append(\"Milk\")\n",
    "\n",
    "for row in d_normalizedImproved[1:]:\n",
    "    v = False\n",
    "    c = 0\n",
    "    for category in row:\n",
    "        for word in category:\n",
    "            if word in milk:\n",
    "                \n",
    "                d9.append(1)\n",
    "                print(word)\n",
    "                c = 1\n",
    "                v = True\n",
    "                break\n",
    "            if v:\n",
    "                break\n",
    "        if v:\n",
    "            break\n",
    "    if c == 0:        \n",
    "        d9.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in wordsDict:\n",
    "    \n",
    "    invertedPost[key] = sorted(map(int,wordsDict[key].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision = \"\"\n",
    "\n",
    "\n",
    "while True: \n",
    "    \n",
    "    while decision not in [\"r\", \"x\"]:\n",
    "        \n",
    "        print(\"what do you want to do?\\n\")\n",
    "        print(\"r\", \"new search\")\n",
    "        print(\"x\", \"exit\")\n",
    "        decision = input()\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    if decision == \"x\":\n",
    "        print(\"bye\")\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            b = False\n",
    "            print(\"Please search something: \\n\")\n",
    "            s = input()\n",
    "            s = preprocess(s)\n",
    "            f = \"y\"\n",
    "            if len(s) >1:\n",
    "                print(\"Do you want only results containing all your request?\")\n",
    "                print(\"y\")\n",
    "                print(\"n\")\n",
    "                f = -1\n",
    "                while f not in [\"y\",\"n\"]:\n",
    "                    try:\n",
    "                        f = input()\n",
    "                    except:\n",
    "                        continue\n",
    "            print(\"\\nSomething you don't like: (Enter if none.) \\n\")\n",
    "            n = preprocess(input())\n",
    "            print(\"please wait a second...\")\n",
    "            \n",
    "            answer = queryPointers(X,s,n,invertedPost, indices,f)\n",
    "            print(\"we are searching the best fit for your request...\\n\")\n",
    "            answerWeighted = queryPointers(Xweight,s,n,invertedPost, indices,f)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            if answer == []:\n",
    "                print(\"sorry nothing to search :(\")\n",
    "                print(\"\\nplease try again you could be lucky :)\")\n",
    "                print(\"\\n\")\n",
    "                decision = \"n\"\n",
    "                \n",
    "        except:\n",
    "            \n",
    "            try:\n",
    "                print(\"No match...we are trying a partial match...\")\n",
    "\n",
    "                answer = partialQueryPointers(X,s,n,invertedPost, indices)\n",
    "                answerWeighted = partialQueryPointers(Xweight,s,n,invertedPost, indices)\n",
    "                b = True\n",
    "                time.sleep(1)\n",
    "                if answer == []:\n",
    "                    print(\"sorry nothing in our database :(\")\n",
    "                    print(\"\\nplease try again you could be lucky :)\")\n",
    "                    print(\"\\n\")\n",
    "                    decision = \"n\"\n",
    "                    \n",
    "            except:\n",
    "                print(\"sorry n in our database :(\")\n",
    "                print(\"\\nplease try again you could be lucky :)\")\n",
    "                print(\"\\n\")\n",
    "                decision = \"n\"\n",
    "           \n",
    "    while decision != \"n\":\n",
    "            \n",
    "            print(\"Do you prefer to see the result ordered by higher cosine similarity or by category?\")\n",
    "            print(\"(the weighted similarity gives different importance to words contained in different part of the text)\\n\")\n",
    "            if b:\n",
    "                print(\"Attention: you could not obtain a good category result because you obtained only a partial match.\")\n",
    "\n",
    "            while decision not in [\"0\",\"1\",\"2\", \"3\"]:\n",
    "\n",
    "                answer2 = answer[:]\n",
    "                answer2Weighted = answerWeighted[:]\n",
    "                print(\"0\", \"similarity ranking\")\n",
    "                print(\"1\", \"similarity ranking weighted\")\n",
    "                print(\"2\", \"category ranking\")\n",
    "                print(\"3\", \"category ranking weighted\")\n",
    "\n",
    "                decision = input()\n",
    "                \n",
    "            if decision == \"2\" or decision == \"3\":\n",
    "                if decision == \"3\":\n",
    "                    answer2 = answer2Weighted\n",
    "\n",
    "                n = ByCategory(data[0])\n",
    "                if n in [8,9]:\n",
    "                    answer2 = OrderByOther(n,answer2,d8_dict,d9_dict,51)\n",
    "                else:\n",
    "                    if b:\n",
    "                        answer2 = OrderByCategoryPartialMatch(n,answer2,d_normalizedDict,s,51)\n",
    "                    else:\n",
    "                        answer2 = OrderByCategory(n,answer2,d_normalizedDict,s,51)\n",
    "\n",
    "            if answer2 == []:\n",
    "                print(\"\\nNo result for this category.\")\n",
    "                print(\"Please try something else:\\n\")\n",
    "                decision = -1\n",
    "            else:\n",
    "                if decision in [\"0\",\"2\",\"3\"]:\n",
    "                    ans = answer2\n",
    "                elif decision == \"1\":\n",
    "                    ans = answer2Weighted\n",
    "                    \n",
    "                print(\"\\n\")    \n",
    "                print(\"The requested result is:\\n\")\n",
    "                c = 0\n",
    "                \n",
    "                num = {k:v for v,k in enumerate(ans)}\n",
    "                if n != 8:\n",
    "                    for k in ans:\n",
    "                        if c > 50:\n",
    "                            break\n",
    "                        print(num[k],re.sub(\"BBC Food - Recipes - \", \"\",data[k][0]))\n",
    "                        c +=1 \n",
    "                else:\n",
    "                    for k in ans:\n",
    "                        if c > 50:\n",
    "                            break\n",
    "                        print(num[k],re.sub(\"BBC Food - Recipes - \", \"\",data[k][0]), \"\\t\\tCookingTime:\", data[k][4])\n",
    "                        c +=1\n",
    "\n",
    "                d = -1\n",
    "\n",
    "                while d not in list(num.values()):\n",
    "                    print(\"\\nPlease choose a recipe:\\n\")\n",
    "                    try:\n",
    "                        d = int(input())\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                chooseRec(d,num,data,dictRecipes)\n",
    "\n",
    "                print(\"\\nDo you want to do something else with this documents?\")\n",
    "                print(\"y\")\n",
    "                print(\"n\")\n",
    "\n",
    "                while decision not in [\"y\", \"n\"]:\n",
    "\n",
    "                    decision = input()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = invertedPost[\"parmigian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = invertedPost[\"melanz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordsDict[\"parmigian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[3962]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordsDict[\"melanz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess(\"Aubergine 'parmigiana' with fresh tomato (Parmigiana alla melanzane in pomodoro fresco\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
